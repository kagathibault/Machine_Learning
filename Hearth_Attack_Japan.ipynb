{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manipulation des données ###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### Visualisation des données ###\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno  # msno.matrix(df) pour voir les valeurs manquantes\n",
    "from ydata_profiling import ProfileReport  # Génération automatique de rapports EDA\n",
    "\n",
    "### Machine Learning - Prétraitement & Modélisation ###\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE # Gestion du déséquilibre des classes\n",
    "\n",
    "### Machine Learning - Modèles & Sélection de Features ###\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    StackingClassifier\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    roc_auc_score, \n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA / Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du fichier\n",
    "health = pd.read_csv(r\"C:\\Users\\thiba\\Documents\\analyse heart attack japan\\japan_heart_attack_dataset.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la base\n",
    "health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA via un ProfileReport\n",
    "health_profile = ProfileReport(health, explorative=True)\n",
    "health_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes non utile\n",
    "health.drop(columns=[col for col in health.columns if col.startswith('Extra_Column')], inplace=True)\n",
    "health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la base\n",
    "health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des types de données\n",
    "health.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## changement des données texte en données numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement des Yes/No par un booléen\n",
    "bool_columns = [\n",
    "    'Smoking_History', \n",
    "    'Diabetes_History', \n",
    "    'Hypertension_History', \n",
    "    'Family_History', \n",
    "    'Heart_Attack_Occurrence'\n",
    "]\n",
    "\n",
    "health[bool_columns] = health[bool_columns].replace({'Yes': True, 'No': False}).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des colonnes catégorielles à transformer en valeurs booléennes\n",
    "categorical_cols = ['Gender', 'Region', 'Physical_Activity', 'Diet_Quality', 'Alcohol_Consumption']\n",
    "\n",
    "# Remplacement des NaN pour la consommation d'alcool en personne qui n'en consomme pas\n",
    "health['Alcohol_Consumption'].fillna('Ne consomme pas', inplace=True)\n",
    "\n",
    "# Transformation de toutes les colonnes catégorielles en booléens\n",
    "health = pd.get_dummies(health, columns=categorical_cols, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification si tout les changements on était effectué\n",
    "health.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification des corrélations du DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('TkAgg') \n",
    "\n",
    "# Calculer la matrice de corrélation\n",
    "corr_matrix = health.corr()\n",
    "# Configuration de la taille \n",
    "plt.figure(figsize=(14, 12))\n",
    "# Génération de la HeatMap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "# Ajout du titre\n",
    "plt.title('Heatmap des corrélations du DataFrame', fontsize=16)\n",
    "# Affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancement du Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 Charger les données\n",
    "df = health.copy()\n",
    "\n",
    "# 🎯 Définir la cible et les features\n",
    "target_column = \"Heart_Attack_Occurrence\"  \n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# 🎚️ Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 🧪 Séparation en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 📊 Sur-échantillonnage (SMOTE)\n",
    "smote = SMOTE(sampling_strategy=0.7, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 🚀 Modèle de Stacking avec XGBoost et CatBoost\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', XGBClassifier(eval_metric=\"logloss\", scale_pos_weight=2.5, learning_rate=0.05, max_depth=5, n_estimators=300, colsample_bytree=0.8, subsample=0.9, random_state=42)),\n",
    "        ('cat', CatBoostClassifier(verbose=0, class_weights=[1, 5], depth=6, iterations=500, learning_rate=0.03, random_state=42))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "# Entraînement du modèle\n",
    "stacking_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 🔍 Prédictions\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "y_prob_stack = stacking_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 📊 Ajustement du seuil de décision\n",
    "threshold = 0.3  # seuil ajusté pour augmenter la détection des positifs\n",
    "y_pred_adjusted = (y_prob_stack > threshold).astype(int)\n",
    "\n",
    "# 📊 Évaluation\n",
    "print(\"\\n🔹 Stacking Performance (Ajusté) avec seuil modifié :\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_adjusted))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_prob_stack))\n",
    "print(classification_report(y_test, y_pred_adjusted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
